{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.3\n",
      "2.31.0\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "print(bs4.__version__)\n",
    "print(requests.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empezamos el scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Obtener el HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_BASE = 'https://scrapepark.org/spanish/'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Parsear el HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_obtenido,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El método find() nos permite quedarnos con la información asociada a una etiqueta de HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer_h2 = soup.find('h2')\n",
    "print(primer_h2)\n",
    "print(primer_h2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El método find_all() busca todos los elementos de la página con esa etiqueta y devuelve una \"lista\" que los contiene (en realidad devuelve un objeto de la clase bs4.element.ResultSet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_todos=soup.find_all('h2')\n",
    "print(h2_todos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Si usamos el parametro limit=1, emulamos al método find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_uno_solo = soup.find_all('h2',limit=1)\n",
    "print(h2_uno_solo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podemos iterar sobre el objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2=soup.find_all('h2')\n",
    "for i in h2:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_text() para más funcionalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seccion in h2:\n",
    "    print(seccion.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando atributos de las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"heading-container heading-center\" id=\"about\">\n",
      "<h2>¿Por qué comprar con nosotros?</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\" id=\"products\">\n",
      "<h2>Nuestros productos</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h3>Suscríbete para obtener descuentos y ofertas</h3>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h2>Testimonios de clientes</h2>\n",
      "</div>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "divs = soup.find_all('div', class_ = 'heading-container heading-center')\n",
    "for div in divs:\n",
    "    print(div)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todas las etiquetas que tengan el atributo \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScrapePark.org Logo\n",
      "Parque de patinaje\n",
      "Variedad de patinetas en nuestra tienda\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Patineta\n",
      "Cliente\n",
      "Cliente\n",
      "Cliente\n",
      "Logo de ScrapePark.org\n",
      "Logo de freeCodeCamp\n"
     ]
    }
   ],
   "source": [
    "src_todos = soup.find_all('img')\n",
    "for elemento in src_todos:\n",
    "    print(elemento['alt'])\n",
    "    '''if elemento['src'].endswith('.jpg'):\n",
    "        print(elemento)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bajar todas las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,imagen in enumerate(src_todos):\n",
    "    if imagen['src'].endswith('png'):\n",
    "        print(imagen['src'])\n",
    "        r=requests.get(f'https://scrapepark.org/spanish/{imagen['src']}')\n",
    "        with open(f'imagen_{i}.png','wb') as f:\n",
    "            f.write(r.content)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Información de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longboard', '$80', '$85', '$90', '$62', '$150']\n"
     ]
    }
   ],
   "source": [
    "URL_BASE = 'https://scrapepark.org/spanish'\n",
    "URL_TABLA = soup.find_all('iframe')[0]['src']\n",
    "\n",
    "request_tabla = requests.get(f'{URL_BASE}/{URL_TABLA}')\n",
    "\n",
    "html_tabla = request_tabla.text\n",
    "soup_tabla = BeautifulSoup(html_tabla,'html.parser')\n",
    "soup_tabla.find('table')\n",
    "\n",
    "productos_faltantes = soup_tabla.find_all(['th','td'], attrs={'style':'color: red;'})\n",
    "productos_fal = [talle.text for talle in productos_faltantes ]\n",
    "\n",
    "print(productos_fal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producto: Patineta nueva1  | precio: 75\n",
      "producto: Patineta usada2  | precio: 80\n",
      "producto: Patineta nueva3  | precio: 68\n",
      "producto: Patineta usada4  | precio: 70\n",
      "producto: Patineta nueva5  | precio: 75\n",
      "producto: Patineta nueva6  | precio: 58\n",
      "producto: Patineta nueva7  | precio: 80\n",
      "producto: Patineta nueva8  | precio: 35\n",
      "producto: Patineta nueva9  | precio: 165\n",
      "producto: Patineta usada10 | precio: 54\n",
      "producto: Patineta usada11 | precio: 99\n",
      "producto: Patineta nueva12 | precio: 110\n",
      "Patineta nueva1 Patineta usada2 Patineta nueva3 Patineta usada4 Patineta nueva5 Patineta nueva6 Patineta nueva7 Patineta nueva8 Patineta nueva9 Patineta usada10 Patineta usada11 Patineta nueva12\n",
      "75 80 68 70 75 58 80 35 165 54 99 110\n"
     ]
    }
   ],
   "source": [
    "divs = soup.find_all('div', class_='detail-box')\n",
    "productos = []\n",
    "precios = []\n",
    "\n",
    "for div in divs:\n",
    "    if div.h6 is not None and 'Patineta' in div.h5.text:\n",
    "        producto = div.h5.get_text(strip=True)\n",
    "        precio = div.h6.get_text(strip=True).replace('$','')\n",
    "        print(f'producto: {producto:<16} | precio: {precio}')\n",
    "        productos.append(producto)\n",
    "        precios.append(precio)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambios que dependen de la URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scrapepark.org/spanish/contact1\n",
      "Texto que cambia entre páginas en contacto 1 :)\n",
      "https://scrapepark.org/spanish/contact2\n",
      "Texto que cambia entre páginas en contacto 2 :)\n"
     ]
    }
   ],
   "source": [
    "URL_BASE = 'https://scrapepark.org/spanish/contact'\n",
    "\n",
    "for i in range(1,3):\n",
    "    URL_FINAL = f'{URL_BASE}{i}'\n",
    "    print(URL_FINAL)\n",
    "    r = requests.get(URL_FINAL)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    print(soup.h5.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos que no sabemos en que parte de la página se encuentran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\jamir\\AppData\\Local\\Temp\\ipykernel_13648\\229612336.py:11: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  telefonos = soup.find_all(string=re.compile('\\d+-\\d+-\\d+'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[': 4-444-4444']\n"
     ]
    }
   ],
   "source": [
    "# Expresiones regulares\n",
    "import re\n",
    "\n",
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org/spanish'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text\n",
    "\n",
    "# 2.'Parsear' ese HTML\n",
    "soup = BeautifulSoup(html_obtenido,'html.parser')\n",
    "telefonos = soup.find_all(string=re.compile('\\d+-\\d+-\\d+'))\n",
    "print(telefonos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moviendonos por el arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m copyrights \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(string\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m©\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcopyrights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\jamir\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bs4\\element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2435\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "copyrights = soup.find_all(string=re.compile('©'))\n",
    "print(copyrights.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>© 2022 <span>Todos los derechos reservados</span>.\n",
       "        <a href=\"https://html.design/\" rel=\"noopener noreferrer\" target=\"_blank\">Creado con Free Html Templates</a>.\n",
       "      </p>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer_copyright=copyrights[0]\n",
    "primer_copyright.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otro ejemplo con elementos al mismo nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 class=\"menu\">MENÚ</h3>\n"
     ]
    }
   ],
   "source": [
    "menu = soup.find(string=re.compile('MENÚ'))\n",
    "print(menu.parent)\n",
    "#menu.parent.find_next_siblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentario sobre exepciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descuentos\n",
      "Aprovechá nuestras ofertas.\n"
     ]
    }
   ],
   "source": [
    "string_a_buscar = ['Descuentos','ofertas']\n",
    "\n",
    "for string in string_a_buscar:\n",
    "    try:\n",
    "        resultado= soup.find(string=re.compile(string))\n",
    "        print(resultado.text)\n",
    "    except AttributeError :\n",
    "        print(f'El string {string} no fue encontrado')           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almacenamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "productos.insert(0,'productos')\n",
    "precios.insert(0,'precios')\n",
    "datos = dict(zip(productos,precios))\n",
    "with open('datos.csv','w') as f:\n",
    "    w= csv.writer(f)\n",
    "    w.writerows(datos.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_='https://scrapepark.org/spanish/'\n",
    "request=requests.get(URL_)\n",
    "soup_= BeautifulSoup(request.text,'html.parser')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Las patinetas que salgan menos que $68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patineta nueva6\n",
      "Patineta nueva8\n",
      "Patineta usada10\n"
     ]
    }
   ],
   "source": [
    "patinetas = soup_.find_all('div', class_='detail-box' )\n",
    "for patineta in patinetas:\n",
    "    if (patineta.h6 is not None) and ('Patineta' in patineta.h5.text):\n",
    "        if int(patineta.h6.get_text(strip=True).replace('$','')) < 68 :\n",
    "            print(patineta.h5.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Las patinetas que en su nombre tengan un número mayor a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patineta usada 4\n",
      "Patineta nueva 5\n",
      "Patineta nueva 6\n",
      "Patineta nueva 7\n",
      "Patineta nueva 8\n",
      "Patineta nueva 9\n",
      "Patineta usada 10\n",
      "Patineta usada 11\n",
      "Patineta nueva 12\n"
     ]
    }
   ],
   "source": [
    "for patineta in patinetas:\n",
    "    if (patineta.h5 is not None) and ('Patineta' in patineta.h5.text) :\n",
    "        if int(patineta.h5.text.strip().split(' ')[2]) > 3:\n",
    "            print(patineta.h5.text.strip())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Traer cualquier texto de la pagina que tenga la palabra descuento u oferta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descuentos\n",
      "Aprovechá nuestras ofertas.\n"
     ]
    }
   ],
   "source": [
    "for palabra in  ['Descuentos','ofertas'] :\n",
    "    try:\n",
    "        texto = soup_.find(string= re.compile(palabra))\n",
    "        print(texto.text)\n",
    "    except AttributeError:\n",
    "        print(f'No se encontro la palabra {palabra} en el HTML')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generar un archivo .csv con dos columnas: Una conteniendo el nombre del cliente y otra su testimonio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cliente 1', 'Cliente 2', 'Cliente 3']\n",
      "['Los productos me encantaron y los precios son muy buenos. Lo recomiendo.', '¡La calidad y variedad de patinetas es impresionante! Definitivamente volveré a comprar.', 'Estoy muy conforme. Hay muchas patinetas y los diseños son fantásticos.']\n",
      "     Cliente                                         Comentario\n",
      "0  Cliente 1  Los productos me encantaron y los precios son ...\n",
      "1  Cliente 2  ¡La calidad y variedad de patinetas es impresi...\n",
      "2  Cliente 3  Estoy muy conforme. Hay muchas patinetas y los...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clientes=[]\n",
    "comentarios=[]\n",
    "clientes_ = soup_.find_all('div', class_='detail-box')\n",
    "for cliente in clientes_:\n",
    "    if cliente.h5 is not None and 'Cliente' in cliente.h5.text:\n",
    "        clientes.append(cliente.h5.text.strip())\n",
    "        comentarios.append(cliente.p.text.strip())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Cliente':clientes,\n",
    "    'Comentario':comentarios\n",
    "})\n",
    "\n",
    "df.to_csv('clientes.csv')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
